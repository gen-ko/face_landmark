{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from face_landmark import model\n",
    "from face_landmark import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\r\n"
     ]
    }
   ],
   "source": [
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "dump_dir = '/barn2/yuan/datasets/300W_LP_mini/json'\n",
    "data_iterator = load_dataset.DatasetIteratorWithHeatmap(dump_dir=dump_dir)\n",
    "print(len(data_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61225\n"
     ]
    }
   ],
   "source": [
    "dump_dir = '/barn2/yuan/datasets/300W_LP/json'\n",
    "data_iterator = load_dataset.DatasetIteratorWithHeatmap(dump_dir=dump_dir)\n",
    "print(len(data_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del sess0\n",
    "    del sess\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    del graph0\n",
    "    del session\n",
    "except:\n",
    "    pass\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 1.4368111226293776\n",
      "epoch: 1 loss: 1.1972072124481201\n",
      "epoch: 2 loss: 1.0517540739642248\n",
      "epoch: 3 loss: 0.9463422927591536\n",
      "epoch: 4 loss: 0.8636044992340935\n",
      "epoch: 5 loss: 0.7953388161129422\n",
      "epoch: 6 loss: 0.7372961507903205\n",
      "epoch: 7 loss: 0.6870713068379296\n",
      "epoch: 8 loss: 0.6428966853353713\n",
      "epoch: 9 loss: 0.6035722196102142\n",
      "epoch: 10 loss: 0.5681571596198611\n",
      "epoch: 11 loss: 0.5359877049922943\n",
      "epoch: 12 loss: 0.5066475023825964\n",
      "epoch: 13 loss: 0.47977151970068616\n",
      "epoch: 14 loss: 0.4550356964270274\n",
      "epoch: 15 loss: 0.4321424000793033\n",
      "epoch: 16 loss: 0.4108474552631378\n",
      "epoch: 17 loss: 0.39097684456242454\n",
      "epoch: 18 loss: 0.3723641468418969\n",
      "epoch: 19 loss: 0.35488467249605393\n",
      "epoch: 20 loss: 0.3384358170959685\n",
      "epoch: 21 loss: 0.32292132410738206\n",
      "epoch: 22 loss: 0.3082752111885283\n",
      "epoch: 23 loss: 0.29442427721288467\n",
      "epoch: 24 loss: 0.281302230225669\n",
      "epoch: 25 loss: 0.2688538233439128\n",
      "epoch: 26 loss: 0.25703509400288266\n",
      "epoch: 27 loss: 0.2457987442612648\n",
      "epoch: 28 loss: 0.23510718759563234\n",
      "epoch: 29 loss: 0.22492983274989659\n",
      "epoch: 30 loss: 0.2152355263630549\n",
      "epoch: 31 loss: 0.20599690824747086\n",
      "epoch: 32 loss: 0.19718824244207805\n",
      "epoch: 33 loss: 0.18878574834929573\n",
      "epoch: 34 loss: 0.180769521329138\n",
      "epoch: 35 loss: 0.17311888602044848\n",
      "epoch: 36 loss: 0.1658133872681194\n",
      "epoch: 37 loss: 0.15883859826458824\n",
      "epoch: 38 loss: 0.152177256014612\n",
      "epoch: 39 loss: 0.1458129965596729\n",
      "epoch: 40 loss: 0.13973064141141045\n",
      "epoch: 41 loss: 0.13391872495412827\n",
      "epoch: 42 loss: 0.128366622245974\n",
      "epoch: 43 loss: 0.12306062959962422\n",
      "epoch: 44 loss: 0.11798918288615015\n",
      "epoch: 45 loss: 0.11314346144596736\n",
      "epoch: 46 loss: 0.10851240944531229\n",
      "epoch: 47 loss: 0.10408594376511043\n",
      "epoch: 48 loss: 0.09985512329472436\n",
      "epoch: 49 loss: 0.09581190720200539\n",
      "epoch: 50 loss: 0.09194656254516707\n",
      "epoch: 51 loss: 0.08825218967265552\n",
      "epoch: 52 loss: 0.0847215751806895\n",
      "epoch: 53 loss: 0.0813473905954096\n",
      "epoch: 54 loss: 0.07812172795335452\n",
      "epoch: 55 loss: 0.07503895751304096\n",
      "epoch: 56 loss: 0.07209348719980982\n",
      "epoch: 57 loss: 0.06927958586149746\n",
      "epoch: 58 loss: 0.06659154904385407\n",
      "epoch: 59 loss: 0.06402290612459183\n",
      "epoch: 60 loss: 0.06156800645920965\n",
      "epoch: 61 loss: 0.05922171576983399\n",
      "epoch: 62 loss: 0.05697987352808317\n",
      "epoch: 63 loss: 0.05483764472107092\n",
      "epoch: 64 loss: 0.052790860128071576\n",
      "epoch: 65 loss: 0.05083551878730456\n",
      "epoch: 66 loss: 0.04896822551058398\n",
      "epoch: 67 loss: 0.04718453147345119\n",
      "epoch: 68 loss: 0.04548071759442488\n",
      "epoch: 69 loss: 0.043853465053770274\n",
      "epoch: 70 loss: 0.0422990077899562\n",
      "epoch: 71 loss: 0.04081479646265507\n",
      "epoch: 72 loss: 0.039397450577881604\n",
      "epoch: 73 loss: 0.038044076412916183\n",
      "epoch: 74 loss: 0.036751345420877136\n",
      "epoch: 75 loss: 0.03551687652038203\n",
      "epoch: 76 loss: 0.034337607212364674\n",
      "epoch: 77 loss: 0.03321170651664337\n",
      "epoch: 78 loss: 0.032136561142073736\n",
      "epoch: 79 loss: 0.031109459180798795\n",
      "epoch: 80 loss: 0.030128568100432556\n",
      "epoch: 81 loss: 0.02919187324328555\n",
      "epoch: 82 loss: 0.028297050649093256\n",
      "epoch: 83 loss: 0.02744262344721291\n",
      "epoch: 84 loss: 0.0266267711089717\n",
      "epoch: 85 loss: 0.025847136249972716\n",
      "epoch: 86 loss: 0.025102469242281385\n",
      "epoch: 87 loss: 0.02439147834148672\n",
      "epoch: 88 loss: 0.023712017056014802\n",
      "epoch: 89 loss: 0.02306284610595968\n",
      "epoch: 90 loss: 0.022442572543190584\n",
      "epoch: 91 loss: 0.02184960266782178\n",
      "epoch: 92 loss: 0.02128294472479158\n",
      "epoch: 93 loss: 0.020741008532543976\n",
      "epoch: 94 loss: 0.02022276870492432\n",
      "epoch: 95 loss: 0.019727044842309423\n",
      "epoch: 96 loss: 0.01925276168104675\n",
      "epoch: 97 loss: 0.018798745444251433\n",
      "epoch: 98 loss: 0.018363955844607618\n",
      "epoch: 99 loss: 0.017947833726389542\n",
      "epoch: 100 loss: 0.01754902820620272\n",
      "epoch: 101 loss: 0.017166957155697875\n",
      "epoch: 102 loss: 0.016800620386170015\n",
      "epoch: 103 loss: 0.016449604959537584\n",
      "epoch: 104 loss: 0.01611263372210993\n",
      "epoch: 105 loss: 0.01578940808152159\n",
      "epoch: 106 loss: 0.015479157834003368\n",
      "epoch: 107 loss: 0.015181215790410837\n",
      "epoch: 108 loss: 0.01489524051754011\n",
      "epoch: 109 loss: 0.014620401430875063\n",
      "epoch: 110 loss: 0.014356146204388805\n",
      "epoch: 111 loss: 0.01410198470370637\n",
      "epoch: 112 loss: 0.013857654709782865\n",
      "epoch: 113 loss: 0.013622402782655425\n",
      "epoch: 114 loss: 0.01339576972855462\n",
      "epoch: 115 loss: 0.01317730892656578\n",
      "epoch: 116 loss: 0.01296662947990828\n",
      "epoch: 117 loss: 0.012763294960475631\n",
      "epoch: 118 loss: 0.01256702421233058\n",
      "epoch: 119 loss: 0.012377335845182339\n",
      "epoch: 120 loss: 0.012194130207515426\n",
      "epoch: 121 loss: 0.01201692254592975\n",
      "epoch: 122 loss: 0.011845567315402959\n",
      "epoch: 123 loss: 0.011679611324022213\n",
      "epoch: 124 loss: 0.011519007333036926\n",
      "epoch: 125 loss: 0.011363239182780186\n",
      "epoch: 126 loss: 0.011212290005965365\n",
      "epoch: 127 loss: 0.011065813195374277\n",
      "epoch: 128 loss: 0.010923504622446166\n",
      "epoch: 129 loss: 0.010785424564447667\n",
      "epoch: 130 loss: 0.010651045478880405\n",
      "epoch: 131 loss: 0.010520518084781038\n",
      "epoch: 132 loss: 0.010393328757749664\n",
      "epoch: 133 loss: 0.010269697910795609\n",
      "epoch: 134 loss: 0.010149248151315583\n",
      "epoch: 135 loss: 0.010031927997867266\n",
      "epoch: 136 loss: 0.009917458519339561\n",
      "epoch: 137 loss: 0.009805985105534395\n",
      "epoch: 138 loss: 0.009697006342725622\n",
      "epoch: 139 loss: 0.00959064651073681\n",
      "epoch: 140 loss: 0.009486730365703503\n",
      "epoch: 141 loss: 0.009385239953796068\n",
      "epoch: 142 loss: 0.009286034205514524\n",
      "epoch: 143 loss: 0.009188915499382548\n",
      "epoch: 144 loss: 0.009093955935289463\n",
      "epoch: 145 loss: 0.00900110273828937\n",
      "epoch: 146 loss: 0.008910048701283004\n",
      "epoch: 147 loss: 0.008820838605364164\n",
      "epoch: 148 loss: 0.00873334377279712\n",
      "epoch: 149 loss: 0.008647522526896663\n",
      "epoch: 150 loss: 0.008563310218354067\n",
      "epoch: 151 loss: 0.008480764382208386\n",
      "epoch: 152 loss: 0.00839960696693096\n",
      "epoch: 153 loss: 0.00832001632079482\n",
      "epoch: 154 loss: 0.008241840353649523\n",
      "epoch: 155 loss: 0.008165030041709542\n",
      "epoch: 156 loss: 0.008089460639490021\n",
      "epoch: 157 loss: 0.008015380163366595\n",
      "epoch: 158 loss: 0.007942479233153991\n",
      "epoch: 159 loss: 0.007870787211383382\n",
      "epoch: 160 loss: 0.0078003555277569425\n",
      "epoch: 161 loss: 0.0077310067135840654\n",
      "epoch: 162 loss: 0.007662845180473394\n",
      "epoch: 163 loss: 0.007595682439083855\n",
      "epoch: 164 loss: 0.007529601196034087\n",
      "epoch: 165 loss: 0.007464592422669132\n",
      "epoch: 166 loss: 0.007400430402615004\n",
      "epoch: 167 loss: 0.007337286240524716\n",
      "epoch: 168 loss: 0.007275085741033156\n",
      "epoch: 169 loss: 0.00721377439589964\n",
      "epoch: 170 loss: 0.007153350290738874\n",
      "epoch: 171 loss: 0.007093832802234424\n",
      "epoch: 172 loss: 0.007035045781069332\n",
      "epoch: 173 loss: 0.0069772131327125765\n",
      "epoch: 174 loss: 0.006920077087771561\n",
      "epoch: 175 loss: 0.006863844167027209\n",
      "epoch: 176 loss: 0.006808307642738025\n",
      "epoch: 177 loss: 0.006753574203078945\n",
      "epoch: 178 loss: 0.006699592366607653\n",
      "epoch: 179 loss: 0.006646280978909797\n",
      "epoch: 180 loss: 0.00659358498847319\n",
      "epoch: 181 loss: 0.006541584980570608\n",
      "epoch: 182 loss: 0.006490245952995287\n",
      "epoch: 183 loss: 0.0064395634302248555\n",
      "epoch: 184 loss: 0.006389501116548975\n",
      "epoch: 185 loss: 0.006340113804779119\n",
      "epoch: 186 loss: 0.006291258329939511\n",
      "epoch: 187 loss: 0.006243104994710948\n",
      "epoch: 188 loss: 0.006195495060334603\n",
      "epoch: 189 loss: 0.006148473075073626\n",
      "epoch: 190 loss: 0.006101993197161291\n",
      "epoch: 191 loss: 0.006056070250148575\n",
      "epoch: 192 loss: 0.006010719704338246\n",
      "epoch: 193 loss: 0.005965823359373543\n",
      "epoch: 194 loss: 0.005921557856102784\n",
      "epoch: 195 loss: 0.005877745182563861\n",
      "epoch: 196 loss: 0.005834439588296745\n",
      "epoch: 197 loss: 0.005791544448584318\n",
      "epoch: 198 loss: 0.0057493333653029464\n",
      "epoch: 199 loss: 0.0057074563422550755\n"
     ]
    }
   ],
   "source": [
    "graph0 = tf.Graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(target='', graph=graph0, config=config) as sess:\n",
    "    image_tensor = tf.placeholder(dtype=tf.uint8, shape=[None, None, None, 3])\n",
    "    x1 = (tf.cast(x=image_tensor, dtype=tf.float32) * 2.0 / 255.0) - 1.0\n",
    "    x2 = tf.image.resize_images(x1, size=(256, 256))\n",
    "    heatmap_inferred_tensors = model.fan(x=x2, num_modules=1)\n",
    "    heatmap_inferred_t1_tensor = heatmap_inferred_tensors[0]\n",
    "    heatmap_groundtruth_tensor = tf.placeholder(dtype=tf.float32, shape=[None, 64, 64, 68])\n",
    "    loss_op = tf.losses.mean_squared_error(labels=heatmap_groundtruth_tensor, predictions=heatmap_inferred_t1_tensor)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=0.00001).minimize(loss_op)\n",
    "    \n",
    "    \n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    sess.run(init_op)\n",
    "    \n",
    "    n_epoch = 200\n",
    "    n_steps = len(data_iterator)\n",
    "\n",
    "    for i_epoch in range(n_epoch):\n",
    "        loss = 0.0\n",
    "        for i_step, (image_sample, heatmap_sample) in enumerate(data_iterator):\n",
    "            loss_i, _ = sess.run([loss_op, train_op], \n",
    "                                  feed_dict={image_tensor:[image_sample],\n",
    "                                             heatmap_groundtruth_tensor:[heatmap_sample]})\n",
    "            loss += loss_i\n",
    "        print('epoch:', i_epoch, 'loss:', loss / n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"IteratorGetNext:0\", shape=(?, 256, 256, 3), dtype=float32)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, 64, 64, 68), dtype=float32)\n",
      "in_channels: 64\n",
      "out_channels: 128\n",
      "in_channels: 128\n",
      "out_channels: 256\n",
      "previous shape: (?, 64, 64, 256)\n",
      "low1 shape: (?, 32, 32, 256)\n",
      "low1 shape: (?, 16, 16, 256)\n",
      "low1 shape: (?, 8, 8, 256)\n",
      "low1 shape: (?, 4, 4, 256)\n",
      "previous shape: (?, 64, 64, 256)\n",
      "low1 shape: (?, 32, 32, 256)\n",
      "low1 shape: (?, 16, 16, 256)\n",
      "low1 shape: (?, 8, 8, 256)\n",
      "low1 shape: (?, 4, 4, 256)\n",
      "previous shape: (?, 64, 64, 256)\n",
      "low1 shape: (?, 32, 32, 256)\n",
      "low1 shape: (?, 16, 16, 256)\n",
      "low1 shape: (?, 8, 8, 256)\n",
      "low1 shape: (?, 4, 4, 256)\n",
      "previous shape: (?, 64, 64, 256)\n",
      "low1 shape: (?, 32, 32, 256)\n",
      "low1 shape: (?, 16, 16, 256)\n",
      "low1 shape: (?, 8, 8, 256)\n",
      "low1 shape: (?, 4, 4, 256)\n",
      "inferred length:  4\n"
     ]
    }
   ],
   "source": [
    "graph0 = tf.Graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "import os\n",
    "\n",
    "with tf.Session(target='', graph=graph0, config=config) as sess:\n",
    "    record_path = '/barn2/yuan/datasets/300W_LP/flat_dataset.record'\n",
    "    dataseto = load_dataset.Dataset()\n",
    "    dataset = dataseto.get_tf_dataset(record_path, batch_size=16)\n",
    "    dataset = dataset.prefetch(buffer_size=200)\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    next_example = iterator.get_next()\n",
    "    image_tensor, heatmap_groundtruth_tensor = next_example\n",
    "\n",
    "    print(image_tensor)\n",
    "    print(heatmap_groundtruth_tensor)\n",
    "    \n",
    "    heatmap_inferred_tensors = model.fan(x=image_tensor, num_modules=4)\n",
    "    print('inferred length: ', len(heatmap_inferred_tensors))\n",
    "    loss_op = 0.0\n",
    "    for heatmap_inferred_tensor in heatmap_inferred_tensors:\n",
    "        loss_op = loss_op + tf.losses.mean_squared_error(labels=heatmap_groundtruth_tensor, predictions=heatmap_inferred_tensor)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=0.00001).minimize(loss_op)\n",
    "\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    sess.run(init_op)\n",
    "    \n",
    "    os.makedirs('./saved_model/face_landmark/20180921_01', exist_ok=True)\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    n_epoch = 200\n",
    "    for i_epoch in range(n_epoch):\n",
    "        sess.run(iterator.initializer)\n",
    "        loss = 0.0\n",
    "        n_steps = 0\n",
    "        step_cnt = 0\n",
    "        while True:\n",
    "            step_cnt += 1\n",
    "            try:\n",
    "                loss_i, _ = sess.run([loss_op, train_op])\n",
    "                loss += loss_i\n",
    "                n_steps += 1\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                saver.save(sess, './saved_model/face_landmark/20180921_01')\n",
    "                break\n",
    "            if step_cnt % 20 == 0:\n",
    "                print('epoch:', i_epoch + 1, 'loss:', loss / n_steps)\n",
    "        print('epoch:', i_epoch + 1, 'loss:', loss / n_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versions {\n",
      "  producer: 27\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph = tf.get_default_graph()\n",
    "print(graph.as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
